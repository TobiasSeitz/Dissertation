\chapter[Co-Designing Persuasive Feedback] {Co-Designing Persuasive \\ Feedback}\label{chap:feedback_modalities}
% lingo: Narrative.

% FOCUS: Involve users in finding ways to provide better/more helpful/more actionable feedback. 
% learn from what they say explicitly, but also explicitly. 
% underlying persuasive principle: \textit{social interaction} (team spirit) between the system and the users. (Forget et al).
% weirich and sasse / Sasse and Felchais --> Socio-Technical System. 
% participatory design methods, open questions, learning from feature requests.
% opportunity: past studies focused on retrospection. We involve users in creating new solutions without a basic starting point. 

% theoretically, magdalena's BA topic could be worth mentioning, too. 
% GOALs.
% 	Design nudges without letting users become aware of that. 
% 	Evaluate 

Goals: 
RQs:
Method: \textbf{Design research}.
Practical Issues: see section on running password studies
Ethical issues: collect plain text passwords? tried in bandwagon study, but there's some resentment. 


Storyline:

%(Intro: 1-2 pages)
Problems:
- nudging approaches have become stale
- some solutions don't focus on the core goals like stronger passwords and/or less reuse
- we found no formal requirement elicitation in 


Goals:
- what do users say they need? derive solutions and design lenses from that. 
- explore solutions that go beyond password meters. (THATS AN OVERALL GOAL)
- put the users first and early (very user-centric)
- learn from their design solutions (co-design) to inform future design decisions.


% 10 + 10 method.
% 

what this chapter can realistically achieve: 
verbal feedback: what is required. qualitative stuff (hint at suggestion trustworthiness, personalization)
nudging: both verbally and visually; dimension: cognitive bias (bandwagon)

\begin{itemize}
	\item[RQ1] Which other feedback solutions/modalities are most feasible to influence password selection?
	\item[RQ2] What are the pros and cons of verbal and non-verbal feedback?
	\item[RQ3] Does feed-\textit{forward} work better than feedback?
\end{itemize}

This chapter reports on a requirements- and design-exploration for password feedback, where we aimed to involve users early in the design process. The project was a collaboration between myself and Caroline Olsienkiewicz, respectively Katharina Schwarz. 

\section{Background and Context}

Design dimensions / aspects of persuasive authentication: PAF Forget \etal \cite{Forget2007PersuasionEducationSecurity}


\section{Eliciting Requirements}
After the literature review (see Part \ref{part:related_work}), there were still open questions about user \textbf{expectations} regarding password strength feedback. Most studies went ahead to test new solutions quantitatively and rarely focused on the intrinsic needs to derive requirements for feedback. In other words, users were often involved very late in the design process, although an earlier involvement could have led to different design decisions. Our goal in the first step of the co-designing process was gathering early insights to learn about the requirements of persuasive interventions in the realm of password authentication. 
%
To narrow down the focus of the requirements, it was important to consider a realistic use-case where the burden of password authentication is relatively high. From related work, we know that password changes are more frequent in work environments, because expiration-policies are still common there \cite{Inglesant2010TrueCostOfUnusablePolicies}. Frequent password changes lead to weaker practices, which might be mitigated by effective password feedback. To find out how we might improve such feedback, we used a lightweight, rapid survey with a large portion of open questions. In the following, we briefly describe the method and findings. 
%Goal: find out what users would expect from password feedback and what they would suggest doing to improve password selection for other users. 
 
%lightweight and rapid iterations

%- Approach: Give users example of \textbf{verbal feedback} 
\subsection{Method}
We opted for an online survey to inform our requirement elicitation for the above described reasons and straightforward data collection. Our questionnaire was centered around the following core research questions:
\begin{itemize}
	\item What so users \textbf{need} from password feedback?
	\item What do they \textbf{miss} in current solutions / interventions?
	\item How would they \textbf{improve} existing feedback?
\end{itemize}

%- qualitative survey 
%	- what works (subjectively) and what doesn't? It's not like people don't know that a study is about password feedback. strength isn't the only dimension. qualitative rating / assessment / perceived helpfulness.
%- What do they miss? 
%- What feedback ideas do they come up with?
%- motivate focus on work environment.
%- usually no choice,
%- expiration policies
%- many password changes leads to creativity deprivation (we should get rid of expiration anyhow)
%- pick up the specific questions b/c they were good

\subsubsection{Prototype}
To ensure that participants have a shared understanding of password feedback mechanisms, we created a small website featuring only a password field and textual feedback beneath. The underlying strength estimation and feedback phrases were based on the zxcvbn library. Warnings and suggestions that come with zxcvbn were translated to German and shown as the users typed inside the password field. The 26 warnings included statements like ``Names and surnames by themselves are easy to guess'' or ``Avoid repeated words and characters''. We tried to simplify the page as much as possible to minimize priming effects, although this was hard to achieve. In particular, we did not show any form of visual feedback to explore whether this is a need that participants mentioned often. Instead, we showed password score in the form ``strength: 2/5''.  The page introduced the scenario (old password at work has expired) and asked participants to create a new password that would fulfill the composition policy of the participant's current employer. The composition policy, however, was not enforced, but we probed it in the questionnaire. We did not log the passwords whatsoever, since this was not the focus of this study. This was disclosed to participants and they could decide to drop out of the study if they were still uncomfortable with providing a new password.  

\subsubsection{Questionnaire}
They survey questionnaire included 37 questions, many of which are quick single- and multiple-selection items to collect context information (e.g. demographics, semantic differentials, social desirability scale). This information would help us assess the value and relative importance of qualitative statements that followed. The core of the questionnaire is formed by eleven items about password feedback, six of which were open questions, e.g. what would need to be changed to make the feedback more comprehensible and how password creation could be facilitated. Moreover, we inquired coping strategies at work and personal password behaviors to derive further requirements. During this part of the questionnaire, we added an \textit{instructional manipulation check}, i.e. an attention check, to filter out participants that were only trying to complete the survey as fast as possible to receive the incentive \cite{Oppenheimer2009InstructionalManipulationChecks}. This is a well-known issue with crowd-sourced survey data, and the attention checks can effectively reduce the risk of low-quality data. The items were randomized where necessary, but the overall structure was the same for all participants, i.e. there were no independent variables. 

\subsubsection{Sample}
We recruited participants via Prolific \footurl{https://prolific.ac}{06.03.2018} which provided similar crowd-sourcing features as Amazon's Mechanical Turk, but has a stronger focus on research surveys. Since \gls{mTurk} does not allow German users to sign up, Prolific is one of the best alternatives because of its large user panel. We screened for German language proficiency via Prolific's internal screening tool. The survey also required participants to be employed and using alphanumeric passwords in their work environment on a regular basis. 
From the 87 users who started the survey, we had to eliminate 47 responses based on previously defined exclusion criteria: incomplete or mechanically translated, incomprehensible answers; failure to complete the instructional manipulation check \cite{Oppenheimer2009InstructionalManipulationChecks}; and fourth-quartile scores on the social desirability scale. The remaining 40 respondents had a diverse educational and professional background, but the largest part (n=15, 37.5\%) held positions in IT or online media. Sixteen were female (40\%) and 24 male (60\%). They were aged between 20 and 53 ($M=32, SD=7$). As an incentive, participants received 1.50€ for approximately 15 minutes worth their time, which meets Prolific's guidelines. 

\subsubsection{Analysis Approach}
We performed structured, iterative thematic analysis of the qualitative data. This approach is inspired by Grounded  Theory and useful for exploring sentiment and mental models early in the design process \cite{Strauss1990}. It consisted of three distinct parts: open coding, axial coding and a final selective coding stage. In the first stage, the data is labeled with an unlimited number of fitting codes. Next, the codes are grouped and abstracted. A second coder independently put the codes into the groups. Differences were discussed until a common solution was found. Finally, the number of code-groups are reduced to the essential themes that best describe the thinking processes, or as in our case, the requirements. 


% TODO: 5 central codes: more info, encouragement through personalization, visual representation (+ convince that strength is beneficial - or when, and bad policy designs)
% first step (open): 267 codes, positive attitude towards password selection support; those who were negative about the support indicated that they are confident enough to go without it. 
% second step: (aggregate topics), but now consider topics across different questions. 
% third step:
\subsection{Overall Results and Central Themes}
% general results

Overall participants were positive about receiving support during password selection, often because ``any kind of help is good help''. Some stated they were convinced that feedback like this helps. The primary benefits they mentioned were reduced frustration and simplification, because it gives reassurance. The latter is a direct lead to the Persuasive Authentication Framework \cite{Forget2007PersuasionEducationSecurity}. If participants were negative about password feedback (n=4), their primary qualm was that they were convinced to achieve strong passwords without external help. In the following, we present the central themes in participants' statements. Multiple coding stages, discussions, and the selection tasks helped us identify overarching needs: \textbf{Show}, \textbf{Explain}, \textbf{Help}, \textbf{Empower}. To keep the narrative coherent, we omit all corollary results that did not guide further research steps. These are reported in higher detail in C. Olsienkiewicz' thesis \cite{Olsienkiewicz2016BAThesis}. 

\subsubsection{Show}
%most important category.
Show appears to be the most important category because at least one answer from each participant could be put into this code. Unsurprisingly, participants preferred \textbf{visual feedback} over verbal feedback. Our prototype refrained from graphical elements entirely, but participants wanted a visual representation of strength. Most notably, a ``horizontal bar'' was mentioned, i.e. a simple password meter. Some participants felt that verbal strength categories are patronizing. ``Colors'' and ``steps'' were commonly mentioned. This theme echoes Ur \etal's quantitative findings \cite{Ur2017DataDrivenPWMeter}.

At the same time, the ``Show'' theme encompasses that participants would like the password reset form to \textit{show} what it expects from the user. If digits or symbols are expected, the feedback should \textit{show} their impact on the users' security or show the risks that are taken by not including symbols and digits. P4 mentioned that if old passwords are disallowed, then these passwords should be shown when creating a new one to know what is going to be disallowed. Hence, ``show'' does not only include feed\textit{back}, but also feed\textit{forward} to align expectations. Therefore, compliance is a mutual contract, and the theme again highlights Sasse and Flechais' argumentation that authentication schemes are \textit{socio-technical systems} \cite{Sasse2005UsableSecurityPosition}. 

%PW-Stärke grafisch darstellen
% from selective coding stage:
%Ziffern als Rubrik (Um Effekt zu erfahren)
%Visuelle Darstellung der PW-Stärke
%Schwache PW blockieren
%Wachsender Balken mit mehr als 4 Stufen
%Balken mit Farben, da visuelles FB mehr motivierend als verbales
%PW-Stärke als Zahl unüblich
%Umfang der Stärke von 4 auf 10 erweitern

\subsubsection{Explain}
%TODO etwas mehr stringenz bitteschön. 
When asked what advice they would have expected the feedback to contain, the answers clearly indicated that participants had a fixed notion of what makes a strong password. Verbal feedback, in their view, should point out that digits, symbols, uppercase letters, randomness, and password length are beneficial for password strength. Most of this is in line with findings from previous chapters and related work. It is interesting, though, that this consensus also shows us that the feedback would not be necessary at all, because everyone is on the same page. Responses from participants who unexpectedly received a low strength rating and feedback produced an important aspect: If feedback stands in \textbf{stark contrast} to how the user perceives their password's strength, explanations are both welcome and necessary. ``Why is the password rated only with two out of five stars?'' (P7) ``How precisely is the strength and feedback determined?'' (P34,P28). The desire to understand the rating is hence the key to correct mental models, but needs to be cued by lower-than-anticipated strength ratings. Potentially, past study results pointed towards the inefficacy of password meters, because they were not accompanied by explanations in case the rating contradicted user beliefs. 

The theme sometimes overlaps with ``show'', because once a feedback system \textit{shows} the risks, participants suggested \textit{explaining} them in detail, i.e. explain the consequences of weak passwords. At the same time, a good comprehensible explanation was mentioned to convey the notion that service provides ``knows what they are talking about'' (P1). Thus, ``explanation-design'' is nuanced and essential for those users eager to learn more. Realistically, though, experience tells that not many people actively seek explanations, but our analysis hints at opportunities when strength feedback breaks mental models.
\todo{lower claims, more stringency.}
%Once you start giving feedback (``strong'' or ``weak'') you need to explain how you came to this conclusion. The explanation often leads to more explanations, and there's an endless number of aspects that you could discuss (see this thesis), but that's unfeasible. \\

%Nicht genug Information

%PW-Stärke niedriger als erwartet
% -- more explanation necessary for things that _break_ mental models
%		- \textbf{people want their mental models confirmed ``it should show me that i need to use uppercase letters and symbols to boost strength''.} others: ``add more randomness'' (I guess of the suggestions), focus on length, suggest to use 1 uppercase letter, emphasize that symbols boost strength, 

%Gute Angabe der PW-Stärke
%Mehr Information zu Stärke des PW
%genaueres FB
%Evtl. Angaben präzisieren
%Denkt schon genug über PW zu wissen
%Hat eigene Logik, neue PW zu erstellen
%Nur anwenden, wenn es zu dem PW passt, das er sich im Kopf zurechtgelegt hat
%Risiken nennen
%Risiken von Hacking erklären
%Folgen eines schlechten PW erläutern
%Mehr erklären, was passiert, wenn PW zu einfach ist

%\subsubsection{Feedback needs to be Personalized}
% mainstreamers: might often THINK that they don't know what a strong password is, while
% experts: THINK they know what a strong password is and are therefore resistant to change their attitude
% Persönlicher an Nutzer richten -> Nutzer befolgen Ratschläge von Nutzern

\subsubsection{Help}
%Definiert ein Minimum und hilft, es einzuhalten
%Hilfe/Tipps sorgen für besseres PW
% Vorschläge bringen

%Wollte Maximalstärke erreichen
% Tipps hilfreicher als Warnungen
%Formel zur Zusammenstellung von PW
%Lange Sätze vorschlagen, die man sich merken kann, statt bestimmter Zeichen
%Tipps geben, wie man sich PW merken kann
This theme informs design decisions around suggestions. Eleven participants noted that specific guidance towards a stronger or memorable password might help them. The well-known repertoire of tips, examples, ``formulas'' (P4), generators, mnemonics, etc. was the center of attention. Showing users \textit{examples} was mentioned by two participants to help them understand what makes a ``perfect'' password and is therefore an overlap with the ``Show'' theme. Another two participants had the idea to show ``best practices'' from other users of the service. At the same time, one participant was skeptical about the use of help, because the outcome might be too predictable: ``\textit{The feedback is helpful, but [if everybody takes the advice,] won't that mean that all passwords become too similar?''} (P12). In some way, she was right, because example-passwords can persuade users to mimick the given example and become more vulnerable than before, so the design should respect this concern. One participant hinted at solving this problem by suggesting modifications based on the currently entered password. This is basically Forget \etal's earliest approach to persuade users towards stronger passwords, which was later studied intensively by Shay \etal \cite{Shay2015SpoonfulOfSugar} and Ur \etal \cite{Ur2017DataDrivenPWMeter}. Thus, the participants' expectations are reflected in this line of research.

%show passwords --> corroborates findings from decoy study --> story line could arch over to decoy and use it as motivation (suggesting passwords). 

% personalization:
%not all feedback worked for everyone, and people wanted to know how they can improve their own password, and not just a random strategy
%tension: personalization comes at the price of being more vulnerable

%Zahlen hilfreich, um Entwicklung mitzuverfolgen
%Gibt Gefühl, dass PW stark genug ist
%Hat deshalb starkes PW gewählt

\subsection{Empower}
The three aforementioned themes flow into the final one: \textbf{empowering} users to be creative, put suggestions into practice, and to be confident in their choice. Most notably, the concept of restricting characters and limiting password strength was a primary concern. Although, we initially would not have considered composition policies as ``feedback'', the participants made a fair points: a rejected password from the policy is a feedback mechanism. However, rejection can easily be perceived as destructive feedback, which manifested in the negative experiences participants mentioned in their statements. Instead, combining ``Show'', ``Explain'', ``Help'' can become a full-fledged creativity support tool: Showing what can be improved, explain why, and help with a jump start through demonstrating alternative ways, while allowing to explore others.

%Although we did not see that as ``feedback'', the policy during password creation is an integral part of the feedback.
%Do not put unnecessary restrictions on users. Empower them to use any symbol and length that they like. 

% Mehr kreatives FB, das Nutzer dazu bringt, erinnerbare aber sichere PW zu erstellen

%Ganze Sätze erlauben
%Zeichenbegrenzung aufheben
%Unsinnige Zeichenverbote aufheben
%Durch FB kann die Qualität des Services gesteigert werden
%klare Anweisungen, die man befolgen kann

\subsection{Limitations}
The insights should be implemented with the study's limitations in mind. Overall, the themes we found are a small snapshot of user needs and need further consolidation for production-level solutions. 

First, we were surprised that so many English-speaking users from the Prolific panel were able to make it through the platform's screening process. Thus, we had to discard many responses where we were unsure about the participant's language skills. Ideally, we should have introduced a small passage of prose to which the participants answers 2-3 comprehension questions. However, we failed to anticipate this until the data was in and also did not plan the budget for the study accordingly. For the remaining participants, however, we ensured the qualitative responses were solid. 
Also, it would have been feasible to be able to ask follow up questions, which was a caveat of the online study method. The sample we would have been able to recruit for in-person interviews, however, would not have been diverse enough, so we were limited in the range of methods. The number of open questions and the resulting answers were still enough to perform in-depth analyses and led to interesting findings. %Since we aimed to move the project forward quickly and iteratively, we also 

%self report (work password) 
%biased // to much priming. should have posed more open general questions in the beginning before launching the prototype website, but this way everyone had the same experience of the basic functionality of password feedback. 

%- pre study results:
%- too many password changes (see above)
%- like to be supported in more creative ways. (Ford issue -- people don't see the bigger picture).
%
%- Analysis steps: open / axial 1 / axial 2 / selective
%- Take Aways / Themes: (codebook Caroline is very helpful here).
%	- better personalization
%	- make strength easier to gauge (maybe. compare to others to justify bandwagon study)
%		- communicate risks realistically
%		- explain what happens when password is too weak
%			- challenge: users don't always want to hear this, it's unrealistic.
%			- positivity, reinforcement.
%			- intrinsic goal: motivate yourself! become enabled, empowered to act differently.
%	- user concerns regarding strength feedback:
%		- if everybody creates passwords based on this feedback, they become too similar and thus insecure?
%		- authoritative character
%		- no cynicism
%	- more creativity support to create stronger passwords (kind of verbatim:)
%		- suggestions
%		- formula to create a strong password. 
%		- show how to be creative 
%		- need to ``feel'' secure
%	- Visualization:
%		- PW Meter
%		- Character categories.
%	- interesting side results: 
%		- \textbf{people want their mental models confirmed ``it should show me that i need to use uppercase letters and symbols to boost strength''.} others: ``add more randomness'' (I guess of the suggestions), focus on length, suggest to use 1 uppercase letter, emphasize that symbols boost strength, 
		
\section{Participatory Design of Password Feedback}
GOAL: design session to actually teach us more about the requirements, not necessarily about the solutions. The prototypical and conjoint solutions tell us about the expectations and needs of users regarding password feedback. 

(condense to 4 pages)
Second Step - Katharina: 
- Involve users in the design of a novel feedback solution
	- participatory design session
	- different groups
- Designs:
	- rewards: beautify page / positive reinforcement from friends (weird suggestions but okay)
	- analogies: time to crack --> goal: better risk assessment for non-experts.
	- playfulness: bubbles / vault / slotmachine to make random character replacements more exciting / represent strength contribution of different elements in some way (fruit salad)
- interesting aspects:
	- a lot of the concepts are visualizable with little text.
	- missing: background information.
	
(lessons learned and take-aways: 2-3 pages)
- how did this approach help us now?
- what did we learn?
- why should we look elsewhere?
- put solutions / needs into ``design space grid'':



\subsection{Process Reflection}
What did people say about being involved? What are the opportunities and drawbacks that they saw?
	
\section{Discussion}

\subsection{Requirements}
The feedback needs to...

% in the form of user stories
The user needs to...
% ... sort of a mantra.



-- things ``wear off'' over time --> habituation effects of password feedback --> surprise is an important element. 

\subsection{Current Frameworks and Feedback Systems}
How do the requirements reflect the persuasive authentication framework?

Do password meters and other solutions fulfill the requirements?
Where is potential to improve?



\section{Conclusion}
The overarching themes in Study 1 are interestingly just what makes a \textbf{good teacher}: show how it's done and the consequences of actions, explain background info in more depth (which is filtered out anyhow), help students achieve what the teacher showed, and empower them by giving new possibilities to apply knowledge. So this superbly reflects Weirich and Sasse's AND Forget \etal's notion that persuasion is a tool to \textit{educate and teach}. Where is the nudging part?

--> both verbal and visual feedback need to be combined
the requirements should somehow be related to what's to come in the decoy chapter. E.g. the suggestive and 

trustworthiness of suggestions / feedback was challenged by first participants.


all in all, participants in the survey were somewhat too optimistic compared to quantitative / empirical results.

The way people designed interventions shows their mental models and lets us inform our own design decisions. We are not the users and simply ``knowing it better'' won't get us very far. We have to pick people up where they are to have a chance in designing effective nudges. 

--> empowerment... TODO.

hard to explain so briefly. tension. when and for whom. 


\vspace*{1cm}\noindent
\fbox{
	\hspace{1cm}
	\parbox[c][8cm]{0.7\linewidth}{
		\section*{Take Aways}
		\begin{itemize}[leftmargin=*]
			\item General requirement elicitation showed that users want to have their mental models confirmed with password feedback. They become skeptical if the feedback shows unexpected strength results.
			\item Users have three essential needs regarding password support and feedback systems: \textbf{Show} the behavior and consequences visually, \textit{Explain} things that break mental models, \textbf{Help} resolve conundrums and achieve better behavior. %Sounds trivial, but it's important we confirmed it%
		\end{itemize}
	}
	\hspace{1cm}
}


%Kicked out: (Third Step: Hard to justify co-creation):
%\section{Case Study: Jumping on the Bandwagon}
%focus: design rationale and short qualitative evaluation. 
%aim: gauge general feasibility, quantify effects on small scale. 
%\todo{MA von Saron Mebratu}
%Mention that LastPass already has something like this now. -- find out when they introduced it (write them an email) 
%--> nudging via bias seems interesting, but bandwagon is countered with reactance.